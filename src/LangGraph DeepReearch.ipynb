{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83c90380-9055-4f8d-8710-f159a48c9618",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph>=0.5.4 (from -r ../requirements.txt (line 1))\n  Downloading langgraph-0.6.5-py3-none-any.whl.metadata (6.8 kB)\nCollecting langchain-community>=0.3.9 (from -r ../requirements.txt (line 2))\n  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\nCollecting langchain-openai>=0.3.28 (from -r ../requirements.txt (line 3))\n  Downloading langchain_openai-0.3.30-py3-none-any.whl.metadata (2.4 kB)\nCollecting langchain-anthropic>=0.3.15 (from -r ../requirements.txt (line 4))\n  Downloading langchain_anthropic-0.3.18-py3-none-any.whl.metadata (1.9 kB)\nCollecting langchain-mcp-adapters>=0.1.6 (from -r ../requirements.txt (line 5))\n  Downloading langchain_mcp_adapters-0.1.9-py3-none-any.whl.metadata (10 kB)\nCollecting langchain-deepseek>=0.1.2 (from -r ../requirements.txt (line 6))\n  Downloading langchain_deepseek-0.1.4-py3-none-any.whl.metadata (1.1 kB)\nCollecting langchain-tavily (from -r ../requirements.txt (line 7))\n  Downloading langchain_tavily-0.2.11-py3-none-any.whl.metadata (22 kB)\nCollecting langchain-groq>=0.2.4 (from -r ../requirements.txt (line 8))\n  Downloading langchain_groq-0.3.7-py3-none-any.whl.metadata (2.6 kB)\nCollecting databricks-langchain (from -r ../requirements.txt (line 9))\n  Downloading databricks_langchain-0.7.0-py3-none-any.whl.metadata (2.8 kB)\nCollecting openai>=1.99.2 (from -r ../requirements.txt (line 10))\n  Downloading openai-1.99.9-py3-none-any.whl.metadata (29 kB)\nCollecting tavily-python>=0.5.0 (from -r ../requirements.txt (line 11))\n  Downloading tavily_python-0.7.10-py3-none-any.whl.metadata (7.5 kB)\nCollecting arxiv>=2.1.3 (from -r ../requirements.txt (line 12))\n  Downloading arxiv-2.2.0-py3-none-any.whl.metadata (6.3 kB)\nCollecting pymupdf>=1.25.3 (from -r ../requirements.txt (line 13))\n  Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\nCollecting xmltodict>=0.14.2 (from -r ../requirements.txt (line 14))\n  Downloading xmltodict-0.14.2-py2.py3-none-any.whl.metadata (8.0 kB)\nCollecting linkup-sdk>=0.2.3 (from -r ../requirements.txt (line 15))\n  Downloading linkup_sdk-0.2.8-py3-none-any.whl.metadata (4.4 kB)\nCollecting duckduckgo-search>=3.0.0 (from -r ../requirements.txt (line 16))\n  Downloading duckduckgo_search-8.1.1-py3-none-any.whl.metadata (16 kB)\nCollecting exa-py>=1.8.8 (from -r ../requirements.txt (line 17))\n  Downloading exa_py-1.14.20-py3-none-any.whl.metadata (3.8 kB)\nCollecting requests>=2.32.3 (from -r ../requirements.txt (line 18))\n  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\nCollecting beautifulsoup4==4.13.3 (from -r ../requirements.txt (line 19))\n  Downloading beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\nCollecting python-dotenv>=1.0.1 (from -r ../requirements.txt (line 20))\n  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\nCollecting pytest (from -r ../requirements.txt (line 21))\n  Downloading pytest-8.4.1-py3-none-any.whl.metadata (7.7 kB)\nCollecting httpx>=0.24.0 (from -r ../requirements.txt (line 22))\n  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\nCollecting markdownify>=0.11.6 (from -r ../requirements.txt (line 23))\n  Downloading markdownify-1.2.0-py3-none-any.whl.metadata (9.9 kB)\nCollecting azure-identity>=1.21.0 (from -r ../requirements.txt (line 24))\n  Downloading azure_identity-1.24.0-py3-none-any.whl.metadata (86 kB)\nCollecting azure-search>=1.0.0b2 (from -r ../requirements.txt (line 25))\n  Downloading azure_search-1.0.0b2-py2.py3-none-any.whl.metadata (1.3 kB)\nCollecting azure-search-documents>=11.5.2 (from -r ../requirements.txt (line 26))\n  Downloading azure_search_documents-11.5.3-py3-none-any.whl.metadata (23 kB)\nCollecting rich>=13.0.0 (from -r ../requirements.txt (line 27))\n  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\nCollecting langgraph-cli>=0.3.1 (from langgraph-cli[inmem]>=0.3.1->-r ../requirements.txt (line 28))\n  Downloading langgraph_cli-0.3.6-py3-none-any.whl.metadata (3.8 kB)\nCollecting langsmith>=0.3.37 (from -r ../requirements.txt (line 29))\n  Downloading langsmith-0.4.14-py3-none-any.whl.metadata (14 kB)\nCollecting langchain-google-vertexai>=2.0.25 (from -r ../requirements.txt (line 30))\n  Downloading langchain_google_vertexai-2.0.28-py3-none-any.whl.metadata (5.3 kB)\nCollecting langchain-google-genai>=2.1.5 (from -r ../requirements.txt (line 31))\n  Downloading langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\nCollecting ipykernel>=6.29.5 (from -r ../requirements.txt (line 32))\n  Downloading ipykernel-6.30.1-py3-none-any.whl.metadata (6.2 kB)\nCollecting supabase>=2.15.3 (from -r ../requirements.txt (line 33))\n  Downloading supabase-2.18.1-py3-none-any.whl.metadata (11 kB)\nCollecting mcp>=1.9.4 (from -r ../requirements.txt (line 34))\n  Downloading mcp-1.13.0-py3-none-any.whl.metadata (68 kB)\nCollecting langchain-aws>=0.2.28 (from -r ../requirements.txt (line 35))\n  Downloading langchain_aws-0.2.30-py3-none-any.whl.metadata (4.0 kB)\nCollecting pandas>=2.3.1 (from -r ../requirements.txt (line 36))\n  Downloading pandas-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\nCollecting mlflow (from -r ../requirements.txt (line 37))\n  Downloading mlflow-3.2.0-py3-none-any.whl.metadata (29 kB)\nCollecting soupsieve>1.2 (from beautifulsoup4==4.13.3->-r ../requirements.txt (line 19))\n  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\nRequirement already satisfied: typing-extensions>=4.0.0 in /databricks/python3/lib/python3.11/site-packages (from beautifulsoup4==4.13.3->-r ../requirements.txt (line 19)) (4.10.0)\nCollecting langchain-core>=0.1 (from langgraph>=0.5.4->-r ../requirements.txt (line 1))\n  Downloading langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\nCollecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph>=0.5.4->-r ../requirements.txt (line 1))\n  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\nCollecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph>=0.5.4->-r ../requirements.txt (line 1))\n  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\nCollecting langgraph-sdk<0.3.0,>=0.2.0 (from langgraph>=0.5.4->-r ../requirements.txt (line 1))\n  Downloading langgraph_sdk-0.2.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting pydantic>=2.7.4 (from langgraph>=0.5.4->-r ../requirements.txt (line 1))\n  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\nCollecting xxhash>=3.5.0 (from langgraph>=0.5.4->-r ../requirements.txt (line 1))\n  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nCollecting langchain<1.0.0,>=0.3.26 (from langchain-community>=0.3.9->-r ../requirements.txt (line 2))\n  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\nCollecting SQLAlchemy<3,>=1.4 (from langchain-community>=0.3.9->-r ../requirements.txt (line 2))\n  Downloading sqlalchemy-2.0.43-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\nRequirement already satisfied: PyYAML>=5.3 in /databricks/python3/lib/python3.11/site-packages (from langchain-community>=0.3.9->-r ../requirements.txt (line 2)) (6.0)\nCollecting aiohttp<4.0.0,>=3.8.3 (from langchain-community>=0.3.9->-r ../requirements.txt (line 2))\n  Downloading aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /databricks/python3/lib/python3.11/site-packages (from langchain-community>=0.3.9->-r ../requirements.txt (line 2)) (8.2.2)\nCollecting dataclasses-json<0.7,>=0.5.7 (from langchain-community>=0.3.9->-r ../requirements.txt (line 2))\n  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community>=0.3.9->-r ../requirements.txt (line 2))\n  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community>=0.3.9->-r ../requirements.txt (line 2))\n  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nCollecting numpy>=1.26.2 (from langchain-community>=0.3.9->-r ../requirements.txt (line 2))\n  Downloading numpy-2.3.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\nCollecting tiktoken<1,>=0.7 (from langchain-openai>=0.3.28->-r ../requirements.txt (line 3))\n  Downloading tiktoken-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nCollecting anthropic<1,>=0.60.0 (from langchain-anthropic>=0.3.15->-r ../requirements.txt (line 4))\n  Downloading anthropic-0.64.0-py3-none-any.whl.metadata (27 kB)\nCollecting typing-extensions>=4.0.0 (from beautifulsoup4==4.13.3->-r ../requirements.txt (line 19))\n  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\nCollecting groq<1,>=0.30.0 (from langchain-groq>=0.2.4->-r ../requirements.txt (line 8))\n  Downloading groq-0.31.0-py3-none-any.whl.metadata (16 kB)\nCollecting databricks-ai-bridge>=0.7.0 (from databricks-langchain->-r ../requirements.txt (line 9))\n  Downloading databricks_ai_bridge-0.7.0-py3-none-any.whl.metadata (6.2 kB)\nCollecting databricks-connect<16.4,>=16.1.1 (from databricks-langchain->-r ../requirements.txt (line 9))\n  Downloading databricks_connect-16.1.6-py2.py3-none-any.whl.metadata (2.6 kB)\nCollecting databricks-vectorsearch>=0.50 (from databricks-langchain->-r ../requirements.txt (line 9))\n  Downloading databricks_vectorsearch-0.57-py3-none-any.whl.metadata (2.8 kB)\nCollecting unitycatalog-langchain>=0.2.0 (from unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain->-r ../requirements.txt (line 9))\n  Downloading unitycatalog_langchain-0.2.0-py3-none-any.whl.metadata (6.5 kB)\nCollecting anyio<5,>=3.5.0 (from openai>=1.99.2->-r ../requirements.txt (line 10))\n  Downloading anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.99.2->-r ../requirements.txt (line 10)) (1.7.0)\nCollecting jiter<1,>=0.4.0 (from openai>=1.99.2->-r ../requirements.txt (line 10))\n  Downloading jiter-0.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\nCollecting sniffio (from openai>=1.99.2->-r ../requirements.txt (line 10))\n  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\nCollecting tqdm>4 (from openai>=1.99.2->-r ../requirements.txt (line 10))\n  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\nCollecting feedparser~=6.0.10 (from arxiv>=2.1.3->-r ../requirements.txt (line 12))\n  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\nCollecting click>=8.1.8 (from duckduckgo-search>=3.0.0->-r ../requirements.txt (line 16))\n  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\nCollecting primp>=0.15.0 (from duckduckgo-search>=3.0.0->-r ../requirements.txt (line 16))\n  Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nCollecting lxml>=5.3.0 (from duckduckgo-search>=3.0.0->-r ../requirements.txt (line 16))\n  Downloading lxml-6.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: charset_normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests>=2.32.3->-r ../requirements.txt (line 18)) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests>=2.32.3->-r ../requirements.txt (line 18)) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests>=2.32.3->-r ../requirements.txt (line 18)) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests>=2.32.3->-r ../requirements.txt (line 18)) (2023.7.22)\nCollecting iniconfig>=1 (from pytest->-r ../requirements.txt (line 21))\n  Downloading iniconfig-2.1.0-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: packaging>=20 in /databricks/python3/lib/python3.11/site-packages (from pytest->-r ../requirements.txt (line 21)) (23.2)\nCollecting pluggy<2,>=1.5 (from pytest->-r ../requirements.txt (line 21))\n  Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\nRequirement already satisfied: pygments>=2.7.2 in /databricks/python3/lib/python3.11/site-packages (from pytest->-r ../requirements.txt (line 21)) (2.15.1)\nCollecting httpcore==1.* (from httpx>=0.24.0->-r ../requirements.txt (line 22))\n  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\nCollecting h11>=0.16 (from httpcore==1.*->httpx>=0.24.0->-r ../requirements.txt (line 22))\n  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: six<2,>=1.15 in /usr/lib/python3/dist-packages (from markdownify>=0.11.6->-r ../requirements.txt (line 23)) (1.16.0)\nRequirement already satisfied: azure-core>=1.31.0 in /databricks/python3/lib/python3.11/site-packages (from azure-identity>=1.21.0->-r ../requirements.txt (line 24)) (1.32.0)\nRequirement already satisfied: cryptography>=2.5 in /databricks/python3/lib/python3.11/site-packages (from azure-identity>=1.21.0->-r ../requirements.txt (line 24)) (41.0.3)\nCollecting msal>=1.30.0 (from azure-identity>=1.21.0->-r ../requirements.txt (line 24))\n  Downloading msal-1.33.0-py3-none-any.whl.metadata (11 kB)\nCollecting msal-extensions>=1.2.0 (from azure-identity>=1.21.0->-r ../requirements.txt (line 24))\n  Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\nCollecting msrest>=0.6.10 (from azure-search>=1.0.0b2->-r ../requirements.txt (line 25))\n  Downloading msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\nCollecting azure-common>=1.1 (from azure-search-documents>=11.5.2->-r ../requirements.txt (line 26))\n  Downloading azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\nRequirement already satisfied: isodate>=0.6.0 in /databricks/python3/lib/python3.11/site-packages (from azure-search-documents>=11.5.2->-r ../requirements.txt (line 26)) (0.7.2)\nCollecting markdown-it-py>=2.2.0 (from rich>=13.0.0->-r ../requirements.txt (line 27))\n  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\nCollecting orjson>=3.9.14 (from langsmith>=0.3.37->-r ../requirements.txt (line 29))\n  Downloading orjson-3.11.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\nCollecting requests-toolbelt>=1.0.0 (from langsmith>=0.3.37->-r ../requirements.txt (line 29))\n  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: zstandard>=0.23.0 in /databricks/python3/lib/python3.11/site-packages (from langsmith>=0.3.37->-r ../requirements.txt (line 29)) (0.23.0)\nCollecting bottleneck<2.0.0,>=1.4.2 (from langchain-google-vertexai>=2.0.25->-r ../requirements.txt (line 30))\n  Downloading bottleneck-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\nCollecting google-cloud-aiplatform<2.0.0,>=1.97.0 (from langchain-google-vertexai>=2.0.25->-r ../requirements.txt (line 30))\n  Downloading google_cloud_aiplatform-1.109.0-py2.py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: google-cloud-storage<3.0.0,>=2.18.0 in /databricks/python3/lib/python3.11/site-packages (from langchain-google-vertexai>=2.0.25->-r ../requirements.txt (line 30)) (2.18.2)\nCollecting numexpr<3.0.0,>=2.8.6 (from langchain-google-vertexai>=2.0.25->-r ../requirements.txt (line 30))\n  Downloading numexpr-2.11.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\nCollecting pyarrow<20.0.0,>=19.0.1 (from langchain-google-vertexai>=2.0.25->-r ../requirements.txt (line 30))\n  Downloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\nCollecting validators<1,>=0.22.0 (from langchain-google-vertexai>=2.0.25->-r ../requirements.txt (line 30))\n  Downloading validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\nCollecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai>=2.1.5->-r ../requirements.txt (line 31))\n  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\nCollecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai>=2.1.5->-r ../requirements.txt (line 31))\n  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\nRequirement already satisfied: comm>=0.1.1 in /databricks/python3/lib/python3.11/site-packages (from ipykernel>=6.29.5->-r ../requirements.txt (line 32)) (0.1.2)\nRequirement already satisfied: debugpy>=1.6.5 in /databricks/python3/lib/python3.11/site-packages (from ipykernel>=6.29.5->-r ../requirements.txt (line 32)) (1.6.7)\nRequirement already satisfied: ipython>=7.23.1 in /databricks/python3/lib/python3.11/site-packages (from ipykernel>=6.29.5->-r ../requirements.txt (line 32)) (8.25.0)\nCollecting jupyter-client>=8.0.0 (from ipykernel>=6.29.5->-r ../requirements.txt (line 32))\n  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /databricks/python3/lib/python3.11/site-packages (from ipykernel>=6.29.5->-r ../requirements.txt (line 32)) (5.3.0)\nRequirement already satisfied: matplotlib-inline>=0.1 in /databricks/python3/lib/python3.11/site-packages (from ipykernel>=6.29.5->-r ../requirements.txt (line 32)) (0.1.6)\nRequirement already satisfied: nest-asyncio>=1.4 in /databricks/python3/lib/python3.11/site-packages (from ipykernel>=6.29.5->-r ../requirements.txt (line 32)) (1.5.6)\nRequirement already satisfied: psutil>=5.7 in /databricks/python3/lib/python3.11/site-packages (from ipykernel>=6.29.5->-r ../requirements.txt (line 32)) (5.9.0)\nRequirement already satisfied: pyzmq>=25 in /databricks/python3/lib/python3.11/site-packages (from ipykernel>=6.29.5->-r ../requirements.txt (line 32)) (25.1.2)\nRequirement already satisfied: tornado>=6.2 in /databricks/python3/lib/python3.11/site-packages (from ipykernel>=6.29.5->-r ../requirements.txt (line 32)) (6.3.2)\nRequirement already satisfied: traitlets>=5.4.0 in /databricks/python3/lib/python3.11/site-packages (from ipykernel>=6.29.5->-r ../requirements.txt (line 32)) (5.13.0)\nCollecting postgrest==1.1.1 (from supabase>=2.15.3->-r ../requirements.txt (line 33))\n  Downloading postgrest-1.1.1-py3-none-any.whl.metadata (3.5 kB)\nCollecting realtime==2.7.0 (from supabase>=2.15.3->-r ../requirements.txt (line 33))\n  Downloading realtime-2.7.0-py3-none-any.whl.metadata (6.6 kB)\nCollecting supabase-auth==2.12.3 (from supabase>=2.15.3->-r ../requirements.txt (line 33))\n  Downloading supabase_auth-2.12.3-py3-none-any.whl.metadata (6.5 kB)\nCollecting storage3==0.12.1 (from supabase>=2.15.3->-r ../requirements.txt (line 33))\n  Downloading storage3-0.12.1-py3-none-any.whl.metadata (1.9 kB)\nCollecting supabase-functions==0.10.1 (from supabase>=2.15.3->-r ../requirements.txt (line 33))\n  Downloading supabase_functions-0.10.1-py3-none-any.whl.metadata (1.2 kB)\nCollecting deprecation<3.0.0,>=2.1.0 (from postgrest==1.1.1->supabase>=2.15.3->-r ../requirements.txt (line 33))\n  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\nCollecting websockets<16,>=11 (from realtime==2.7.0->supabase>=2.15.3->-r ../requirements.txt (line 33))\n  Downloading websockets-15.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /databricks/python3/lib/python3.11/site-packages (from storage3==0.12.1->supabase>=2.15.3->-r ../requirements.txt (line 33)) (2.8.2)\nCollecting pyjwt<3.0.0,>=2.10.1 (from supabase-auth==2.12.3->supabase>=2.15.3->-r ../requirements.txt (line 33))\n  Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\nCollecting strenum<0.5.0,>=0.4.15 (from supabase-functions==0.10.1->supabase>=2.15.3->-r ../requirements.txt (line 33))\n  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\nCollecting jsonschema>=4.20.0 (from mcp>=1.9.4->-r ../requirements.txt (line 34))\n  Downloading jsonschema-4.25.0-py3-none-any.whl.metadata (7.7 kB)\nCollecting python-multipart>=0.0.9 (from mcp>=1.9.4->-r ../requirements.txt (line 34))\n  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\nCollecting sse-starlette>=1.6.1 (from mcp>=1.9.4->-r ../requirements.txt (line 34))\n  Downloading sse_starlette-3.0.2-py3-none-any.whl.metadata (11 kB)\nCollecting starlette>=0.27 (from mcp>=1.9.4->-r ../requirements.txt (line 34))\n  Downloading starlette-0.47.2-py3-none-any.whl.metadata (6.2 kB)\nCollecting uvicorn>=0.31.1 (from mcp>=1.9.4->-r ../requirements.txt (line 34))\n  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\nCollecting boto3>=1.39.7 (from langchain-aws>=0.2.28->-r ../requirements.txt (line 35))\n  Downloading boto3-1.40.11-py3-none-any.whl.metadata (6.7 kB)\nCollecting numpy>=1.26.2 (from langchain-community>=0.3.9->-r ../requirements.txt (line 2))\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.11/site-packages (from pandas>=2.3.1->-r ../requirements.txt (line 36)) (2022.7)\nCollecting tzdata>=2022.7 (from pandas>=2.3.1->-r ../requirements.txt (line 36))\n  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\nCollecting mlflow-skinny==3.2.0 (from mlflow->-r ../requirements.txt (line 37))\n  Downloading mlflow_skinny-3.2.0-py3-none-any.whl.metadata (30 kB)\nCollecting mlflow-tracing==3.2.0 (from mlflow->-r ../requirements.txt (line 37))\n  Downloading mlflow_tracing-3.2.0-py3-none-any.whl.metadata (19 kB)\nCollecting Flask<4 (from mlflow->-r ../requirements.txt (line 37))\n  Downloading flask-3.1.1-py3-none-any.whl.metadata (3.0 kB)\nCollecting alembic!=1.10.0,<2 (from mlflow->-r ../requirements.txt (line 37))\n  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\nCollecting docker<8,>=4.0.0 (from mlflow->-r ../requirements.txt (line 37))\n  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\nCollecting graphene<4 (from mlflow->-r ../requirements.txt (line 37))\n  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\nCollecting gunicorn<24 (from mlflow->-r ../requirements.txt (line 37))\n  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.11/site-packages (from mlflow->-r ../requirements.txt (line 37)) (3.7.2)\nRequirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.11/site-packages (from mlflow->-r ../requirements.txt (line 37)) (1.3.0)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.11/site-packages (from mlflow->-r ../requirements.txt (line 37)) (1.11.1)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow->-r ../requirements.txt (line 37)) (5.5.0)\nRequirement already satisfied: cloudpickle<4 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow->-r ../requirements.txt (line 37)) (3.0.0)\nRequirement already satisfied: databricks-sdk<1,>=0.20.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow->-r ../requirements.txt (line 37)) (0.40.0)\nCollecting fastapi<1 (from mlflow-skinny==3.2.0->mlflow->-r ../requirements.txt (line 37))\n  Downloading fastapi-0.116.1-py3-none-any.whl.metadata (28 kB)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow->-r ../requirements.txt (line 37)) (3.1.43)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow->-r ../requirements.txt (line 37)) (6.0.0)\nCollecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.2.0->mlflow->-r ../requirements.txt (line 37))\n  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.2.0->mlflow->-r ../requirements.txt (line 37))\n  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow->-r ../requirements.txt (line 37)) (5.29.3)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow->-r ../requirements.txt (line 37)) (0.5.1)\nCollecting langgraph-api<0.3.0,>=0.2.67 (from langgraph-cli[inmem]>=0.3.1->-r ../requirements.txt (line 28))\n  Downloading langgraph_api-0.2.132-py3-none-any.whl.metadata (3.9 kB)\nCollecting langgraph-runtime-inmem>=0.6.0 (from langgraph-cli[inmem]>=0.3.1->-r ../requirements.txt (line 28))\n  Downloading langgraph_runtime_inmem-0.6.13-py3-none-any.whl.metadata (566 bytes)\nCollecting aiohappyeyeballs>=2.5.0 (from aiohttp<\n\n*** WARNING: max output size exceeded, skipping output. ***\n\n MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.2/5.2 MB\u001B[0m \u001B[31m16.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\nDownloading msal-1.33.0-py3-none-any.whl (116 kB)\nDownloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\nDownloading msrest-0.7.1-py3-none-any.whl (85 kB)\nDownloading numexpr-2.11.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (401 kB)\nDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/18.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.1/18.3 MB\u001B[0m \u001B[31m35.1 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m18.3/18.3 MB\u001B[0m \u001B[31m45.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading orjson-3.11.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\nDownloading pluggy-1.6.0-py3-none-any.whl (20 kB)\nDownloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m16.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/42.1 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m23.1/42.1 MB\u001B[0m \u001B[31m139.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━\u001B[0m \u001B[32m26.7/42.1 MB\u001B[0m \u001B[31m65.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━\u001B[0m \u001B[32m36.7/42.1 MB\u001B[0m \u001B[31m46.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m41.9/42.1 MB\u001B[0m \u001B[31m47.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m41.9/42.1 MB\u001B[0m \u001B[31m47.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m42.1/42.1 MB\u001B[0m \u001B[31m32.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading pydantic-2.11.7-py3-none-any.whl (444 kB)\nDownloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/2.0 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m9.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\nDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\nDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\nDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\nDownloading soupsieve-2.7-py3-none-any.whl (36 kB)\nDownloading sqlalchemy-2.0.43-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m24.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading sse_starlette-2.1.3-py3-none-any.whl (9.4 kB)\nDownloading starlette-0.47.2-py3-none-any.whl (72 kB)\nDownloading tiktoken-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.2 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m34.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\nDownloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\nDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\nDownloading unitycatalog_langchain-0.2.0-py3-none-any.whl (5.4 kB)\nDownloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\nDownloading validators-0.35.0-py3-none-any.whl (44 kB)\nDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\nDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\nDownloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\nDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\nDownloading attrs-25.3.0-py3-none-any.whl (63 kB)\nDownloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\nDownloading blockbuster-1.5.25-py3-none-any.whl (13 kB)\nDownloading botocore-1.40.11-py3-none-any.whl (14.0 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/14.0 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━\u001B[0m \u001B[32m11.8/14.0 MB\u001B[0m \u001B[31m58.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m13.9/14.0 MB\u001B[0m \u001B[31m30.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m13.9/14.0 MB\u001B[0m \u001B[31m30.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m13.9/14.0 MB\u001B[0m \u001B[31m30.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.0/14.0 MB\u001B[0m \u001B[31m11.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading databricks_sdk-0.63.0-py3-none-any.whl (688 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/688.0 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m688.0/688.0 kB\u001B[0m \u001B[31m4.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\nDownloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\nDownloading fastapi-0.116.1-py3-none-any.whl (95 kB)\nDownloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\nDownloading google_cloud_bigquery-3.35.1-py3-none-any.whl (256 kB)\nDownloading packaging-25.0-py3-none-any.whl (66 kB)\nDownloading google_cloud_resource_manager-1.14.2-py3-none-any.whl (394 kB)\nDownloading google_genai-1.30.0-py3-none-any.whl (229 kB)\nDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\nDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\nDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nDownloading greenlet-3.2.4-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (587 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/587.7 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m587.7/587.7 kB\u001B[0m \u001B[31m41.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading grpcio_status-1.62.3-py3-none-any.whl (14 kB)\nDownloading h11-0.16.0-py3-none-any.whl (37 kB)\nDownloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\nDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\nDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nDownloading jsonschema_rs-0.29.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/2.1 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.1/2.1 MB\u001B[0m \u001B[31m62.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\nDownloading langchain_text_splitters-0.3.9-py3-none-any.whl (33 kB)\nDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\nDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\nDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\nDownloading multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\nDownloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\nDownloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\nDownloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\nDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\nDownloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\nDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\nDownloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\nDownloading referencing-0.36.2-py3-none-any.whl (26 kB)\nDownloading regex-2025.7.34-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (798 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/798.9 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m798.9/798.9 kB\u001B[0m \u001B[31m5.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\nDownloading rpds_py-0.27.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (383 kB)\nDownloading s3transfer-0.13.1-py3-none-any.whl (85 kB)\nDownloading shapely-2.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.1 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.1/3.1 MB\u001B[0m \u001B[31m57.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\nDownloading structlog-25.4.0-py3-none-any.whl (68 kB)\nDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\nDownloading truststore-0.10.4-py3-none-any.whl (18 kB)\nDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\nDownloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\nDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\nDownloading websockets-15.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\nDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\nDownloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (348 kB)\nDownloading mako-1.3.10-py3-none-any.whl (78 kB)\nDownloading unitycatalog_ai-0.3.1-py3-none-any.whl (66 kB)\nDownloading grpc_google_iam_v1-0.14.2-py3-none-any.whl (19 kB)\nDownloading h2-4.2.0-py3-none-any.whl (60 kB)\nDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\nDownloading unitycatalog_client-0.3.0-py3-none-any.whl (159 kB)\nDownloading aiohttp_retry-2.9.1-py3-none-any.whl (10.0 kB)\nDownloading hpack-4.1.0-py3-none-any.whl (34 kB)\nDownloading hyperframe-6.1.0-py3-none-any.whl (13 kB)\nBuilding wheels for collected packages: sgmllib3k, forbiddenfruit\n  Building wheel for sgmllib3k (setup.py): started\n  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6047 sha256=5b1526b6e8d15e2c9329f5abdeb9d6662fb019ff7c63384939c5b10260f593c9\n  Stored in directory: /home/spark-89eafeaa-68a1-4d22-977d-95/.cache/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n  Building wheel for forbiddenfruit (setup.py): started\n  Building wheel for forbiddenfruit (setup.py): finished with status 'done'\n  Created wheel for forbiddenfruit: filename=forbiddenfruit-0.1.4-py3-none-any.whl size=21791 sha256=1d9065c4169540ca19d3e6e4701866a988f65d2db5c33a3075fb9da170dbee9b\n  Stored in directory: /home/spark-89eafeaa-68a1-4d22-977d-95/.cache/pip/wheels/a3/09/38/5a94e2df4ae8f2cfc8053997507ad46b07009af3afc34a9a9c\nSuccessfully built sgmllib3k forbiddenfruit\nInstalling collected packages: strenum, sgmllib3k, forbiddenfruit, filetype, azure-common, xxhash, xmltodict, websockets, validators, tzdata, typing-extensions, truststore, tqdm, tenacity, tabulate, structlog, soupsieve, sniffio, rpds-py, requests, regex, python-multipart, python-dotenv, pymupdf, pyjwt, pyarrow, protobuf, propcache, primp, pluggy, packaging, ormsgpack, orjson, numpy, multidict, mdurl, markupsafe, lxml, jsonschema-rs, jsonpointer, jiter, itsdangerous, iniconfig, hyperframe, httpx-sse, hpack, h11, greenlet, graphql-core, frozenlist, feedparser, docstring_parser, click, blockbuster, blinker, attrs, annotated-types, aiohappyeyeballs, yarl, werkzeug, uvicorn, typing-inspection, typing-inspect, tiktoken, SQLAlchemy, shapely, requests-toolbelt, requests-oauthlib, referencing, pytest, pydantic-core, pandas, opentelemetry-api, numexpr, marshmallow, markdown-it-py, Mako, jupyter-client, jsonpatch, jinja2, httpcore, h2, gunicorn, graphql-relay, duckduckgo-search, docker, deprecation, cryptography, bottleneck, botocore, beautifulsoup4, arxiv, anyio, aiosignal, watchfiles, starlette, s3transfer, rich, pydantic, opentelemetry-semantic-conventions, msrest, markdownify, jsonschema-specifications, httpx, grpcio-status, graphene, Flask, dataclasses-json, databricks-sdk, azure-search-documents, alembic, aiohttp, tavily-python, sse-starlette, realtime, pydantic-settings, opentelemetry-sdk, openai, msal, linkup-sdk, langsmith, langgraph-sdk, jsonschema, ipykernel, grpc-google-iam-v1, groq, google-genai, fastapi, databricks-connect, boto3, azure-search, anthropic, aiohttp-retry, unitycatalog-client, supabase-functions, supabase-auth, storage3, postgrest, msal-extensions, mlflow-tracing, mlflow-skinny, mcp, langgraph-cli, langchain-core, google-cloud-resource-manager, google-cloud-bigquery, google-ai-generativelanguage, exa-py, unitycatalog-ai, supabase, mlflow, langgraph-checkpoint, langchain-text-splitters, langchain-openai, langchain-mcp-adapters, langchain-groq, langchain-google-genai, langchain-aws, langchain-anthropic, google-cloud-aiplatform, databricks-vectorsearch, databricks-ai-bridge, azure-identity, langgraph-prebuilt, langchain-google-vertexai, langchain-deepseek, langchain, langgraph, langchain-tavily, langchain-community, unitycatalog-langchain, langgraph-runtime-inmem, langgraph-api, databricks-langchain\n  Attempting uninstall: tzdata\n    Found existing installation: tzdata 2022.1\n    Not uninstalling tzdata at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7\n    Can't uninstall 'tzdata'. No files were found to uninstall.\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.10.0\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7\n    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n  Attempting uninstall: tenacity\n    Found existing installation: tenacity 8.2.2\n    Not uninstalling tenacity at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7\n    Can't uninstall 'tenacity'. No files were found to uninstall.\n  Attempting uninstall: requests\n    Found existing installation: requests 2.31.0\n    Not uninstalling requests at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7\n    Can't uninstall 'requests'. No files were found to uninstall.\n  Attempting uninstall: pyjwt\n    Found existing installation: PyJWT 2.3.0\n    Not uninstalling pyjwt at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7\n    Can't uninstall 'PyJWT'. No files were found to uninstall.\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 14.0.1\n    Not uninstalling pyarrow at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7\n    Can't uninstall 'pyarrow'. No files were found to uninstall.\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 5.29.3\n    Not uninstalling protobuf at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7\n    Can't uninstall 'protobuf'. No files were found to uninstall.\n  Attempting uninstall: packaging\n    Found existing installation: packaging 23.2\n    Not uninstalling packaging at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7\n    Can't uninstall 'packaging'. No files were found to uninstall.\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.23.5\n    Not uninstalling numpy at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7\n    Can't uninstall 'numpy'. No files were found to uninstall.\n  Attempting uninstall: click\n    Found existing installation: click 8.0.4\n    Not uninstalling click at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7\n    Can't uninstall 'click'. No files were found to uninstall.\n  Attempting uninstall: blinker\n    Found existing installation: blinker 1.4\n    Not uninstalling blinker at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7\n    Can't uninstall 'blinker'. No files were found to uninstall.\n  Attempting uninstall: pandas\n    Found existing installation: pandas 1.5.3\n    Not uninstalling pandas at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7\n    Can't uninstall 'pandas'. No files were found to uninstall.\n  Attempting uninstall: jupyter-client\n    Found existing installation: jupyter_client 7.4.9\n    Not uninstalling jupyter-client at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7\n    Can't uninstall 'jupyter_client'. No files were found to uninstall.\n  Attempting uninstall: cryptography\n    Found existing installation: cryptography 41.0.3\n    Not uninstalling cryptography at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7\n    Can't uninstall 'cryptography'. No files were found to uninstall.\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.34.39\n    Not uninstalling botocore at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7\n    Can't uninstall 'botocore'. No files were found to uninstall.\n  Attempting uninstall: s3transfer\n    Found existing installation: s3transfer 0.10.3\n    Not uninstalling s3transfer at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7\n    Can't uninstall 's3transfer'. No files were found to uninstall.\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 1.10.6\n    Not uninstalling pydantic at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7\n    Can't uninstall 'pydantic'. No files were found to uninstall.\n  Attempting uninstall: grpcio-status\n    Found existing installation: grpcio-status 1.69.0\n    Not uninstalling grpcio-status at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7\n    Can't uninstall 'grpcio-status'. No files were found to uninstall.\n  Attempting uninstall: databricks-sdk\n    Found existing installation: databricks-sdk 0.40.0\n    Not uninstalling databricks-sdk at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7\n    Can't uninstall 'databricks-sdk'. No files were found to uninstall.\n  Attempting uninstall: ipykernel\n    Found existing installation: ipykernel 6.28.0\n    Not uninstalling ipykernel at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7\n    Can't uninstall 'ipykernel'. No files were found to uninstall.\n  Attempting uninstall: databricks-connect\n    Found existing installation: databricks-connect 15.4.12\n    Not uninstalling databricks-connect at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7\n    Can't uninstall 'databricks-connect'. No files were found to uninstall.\n  Attempting uninstall: boto3\n    Found existing installation: boto3 1.34.39\n    Not uninstalling boto3 at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7\n    Can't uninstall 'boto3'. No files were found to uninstall.\n  Attempting uninstall: mlflow-skinny\n    Found existing installation: mlflow-skinny 2.11.4\n    Not uninstalling mlflow-skinny at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7\n    Can't uninstall 'mlflow-skinny'. No files were found to uninstall.\nSuccessfully installed Flask-3.1.1 Mako-1.3.10 SQLAlchemy-2.0.43 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiohttp-retry-2.9.1 aiosignal-1.4.0 alembic-1.16.4 annotated-types-0.7.0 anthropic-0.64.0 anyio-4.10.0 arxiv-2.2.0 attrs-25.3.0 azure-common-1.1.28 azure-identity-1.24.0 azure-search-1.0.0b2 azure-search-documents-11.5.3 beautifulsoup4-4.13.3 blinker-1.9.0 blockbuster-1.5.25 boto3-1.40.11 botocore-1.40.11 bottleneck-1.5.0 click-8.2.1 cryptography-44.0.3 databricks-ai-bridge-0.7.0 databricks-connect-16.1.6 databricks-langchain-0.7.0 databricks-sdk-0.63.0 databricks-vectorsearch-0.57 dataclasses-json-0.6.7 deprecation-2.1.0 docker-7.1.0 docstring_parser-0.17.0 duckduckgo-search-8.1.1 exa-py-1.14.20 fastapi-0.116.1 feedparser-6.0.11 filetype-1.2.0 forbiddenfruit-0.1.4 frozenlist-1.7.0 google-ai-generativelanguage-0.6.18 google-cloud-aiplatform-1.109.0 google-cloud-bigquery-3.35.1 google-cloud-resource-manager-1.14.2 google-genai-1.30.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 greenlet-3.2.4 groq-0.31.0 grpc-google-iam-v1-0.14.2 grpcio-status-1.62.3 gunicorn-23.0.0 h11-0.16.0 h2-4.2.0 hpack-4.1.0 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.1 hyperframe-6.1.0 iniconfig-2.1.0 ipykernel-6.30.1 itsdangerous-2.2.0 jinja2-3.1.6 jiter-0.10.0 jsonpatch-1.33 jsonpointer-3.0.0 jsonschema-4.25.0 jsonschema-rs-0.29.1 jsonschema-specifications-2025.4.1 jupyter-client-8.6.3 langchain-0.3.27 langchain-anthropic-0.3.18 langchain-aws-0.2.30 langchain-community-0.3.27 langchain-core-0.3.74 langchain-deepseek-0.1.4 langchain-google-genai-2.1.9 langchain-google-vertexai-2.0.28 langchain-groq-0.3.7 langchain-mcp-adapters-0.1.9 langchain-openai-0.3.30 langchain-tavily-0.2.11 langchain-text-splitters-0.3.9 langgraph-0.6.5 langgraph-api-0.2.132 langgraph-checkpoint-2.1.1 langgraph-cli-0.3.6 langgraph-prebuilt-0.6.4 langgraph-runtime-inmem-0.6.13 langgraph-sdk-0.2.0 langsmith-0.4.14 linkup-sdk-0.2.8 lxml-6.0.0 markdown-it-py-4.0.0 markdownify-1.2.0 markupsafe-3.0.2 marshmallow-3.26.1 mcp-1.13.0 mdurl-0.1.2 mlflow-3.2.0 mlflow-skinny-3.2.0 mlflow-tracing-3.2.0 msal-1.33.0 msal-extensions-1.3.1 msrest-0.7.1 multidict-6.6.4 numexpr-2.11.0 numpy-1.26.4 openai-1.99.9 opentelemetry-api-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 orjson-3.11.2 ormsgpack-1.10.0 packaging-25.0 pandas-2.3.1 pluggy-1.6.0 postgrest-1.1.1 primp-0.15.0 propcache-0.3.2 protobuf-4.25.8 pyarrow-19.0.1 pydantic-2.11.7 pydantic-core-2.33.2 pydantic-settings-2.10.1 pyjwt-2.10.1 pymupdf-1.26.3 pytest-8.4.1 python-dotenv-1.1.1 python-multipart-0.0.20 realtime-2.7.0 referencing-0.36.2 regex-2025.7.34 requests-2.32.4 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 rich-14.1.0 rpds-py-0.27.0 s3transfer-0.13.1 sgmllib3k-1.0.0 shapely-2.1.1 sniffio-1.3.1 soupsieve-2.7 sse-starlette-2.1.3 starlette-0.47.2 storage3-0.12.1 strenum-0.4.15 structlog-25.4.0 supabase-2.18.1 supabase-auth-2.12.3 supabase-functions-0.10.1 tabulate-0.9.0 tavily-python-0.7.10 tenacity-9.1.2 tiktoken-0.11.0 tqdm-4.67.1 truststore-0.10.4 typing-extensions-4.14.1 typing-inspect-0.9.0 typing-inspection-0.4.1 tzdata-2025.2 unitycatalog-ai-0.3.1 unitycatalog-client-0.3.0 unitycatalog-langchain-0.2.0 uvicorn-0.35.0 validators-0.35.0 watchfiles-1.1.0 websockets-15.0.1 werkzeug-3.1.3 xmltodict-0.14.2 xxhash-3.5.0 yarl-1.20.1\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4280d867-d33f-4375-a079-eb8e792e6d72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (3.2.0)\nRequirement already satisfied: mlflow-skinny==3.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from mlflow) (3.2.0)\nRequirement already satisfied: mlflow-tracing==3.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from mlflow) (3.2.0)\nRequirement already satisfied: Flask<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from mlflow) (3.1.1)\nRequirement already satisfied: alembic!=1.10.0,<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from mlflow) (1.16.4)\nRequirement already satisfied: docker<8,>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from mlflow) (7.1.0)\nRequirement already satisfied: graphene<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from mlflow) (3.4.3)\nRequirement already satisfied: gunicorn<24 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from mlflow) (23.0.0)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.11/site-packages (from mlflow) (3.7.2)\nRequirement already satisfied: numpy<3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from mlflow) (1.26.4)\nRequirement already satisfied: pandas<3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from mlflow) (2.3.1)\nRequirement already satisfied: pyarrow<22,>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from mlflow) (19.0.1)\nRequirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.11/site-packages (from mlflow) (1.3.0)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.11/site-packages (from mlflow) (1.11.1)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from mlflow) (2.0.43)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow) (5.5.0)\nRequirement already satisfied: click<9,>=7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow) (8.2.1)\nRequirement already satisfied: cloudpickle<4 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow) (3.0.0)\nRequirement already satisfied: databricks-sdk<1,>=0.20.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow) (0.63.0)\nRequirement already satisfied: fastapi<1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow) (0.116.1)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow) (3.1.43)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow) (6.0.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow) (1.36.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow) (1.36.0)\nRequirement already satisfied: packaging<26 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow) (25.0)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow) (4.25.8)\nRequirement already satisfied: pydantic<3,>=1.10.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow) (2.11.7)\nRequirement already satisfied: pyyaml<7,>=5.1 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow) (6.0)\nRequirement already satisfied: requests<3,>=2.17.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow) (2.32.4)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow) (0.5.1)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow) (4.14.1)\nRequirement already satisfied: uvicorn<1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from mlflow-skinny==3.2.0->mlflow) (0.35.0)\nRequirement already satisfied: Mako in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\nRequirement already satisfied: urllib3>=1.26.0 in /databricks/python3/lib/python3.11/site-packages (from docker<8,>=4.0.0->mlflow) (1.26.16)\nRequirement already satisfied: blinker>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from Flask<4->mlflow) (1.9.0)\nRequirement already satisfied: itsdangerous>=2.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: jinja2>=3.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.6)\nRequirement already satisfied: markupsafe>=2.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from Flask<4->mlflow) (3.0.2)\nRequirement already satisfied: werkzeug>=3.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.3)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.6)\nRequirement already satisfied: graphql-relay<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.0)\nRequirement already satisfied: python-dateutil<3,>=2.7.0 in /databricks/python3/lib/python3.11/site-packages (from graphene<4->mlflow) (2.8.2)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.0.5)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (4.25.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.4.4)\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (10.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (3.0.9)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.11/site-packages (from pandas<3->mlflow) (2022.7)\nRequirement already satisfied: tzdata>=2022.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from pandas<3->mlflow) (2025.2)\nRequirement already satisfied: joblib>=1.1.1 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (2.2.0)\nRequirement already satisfied: greenlet>=1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.4)\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.2.0->mlflow) (2.35.0)\nRequirement already satisfied: starlette<0.48.0,>=0.40.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from fastapi<1->mlflow-skinny==3.2.0->mlflow) (0.47.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.2.0->mlflow) (4.0.11)\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.11/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.2.0->mlflow) (3.11.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.2.0->mlflow) (0.57b0)\nRequirement already satisfied: annotated-types>=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.2.0->mlflow) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.2.0->mlflow) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.2.0->mlflow) (0.4.1)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.2.0->mlflow) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.2.0->mlflow) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.2.0->mlflow) (2023.7.22)\nRequirement already satisfied: h11>=0.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from uvicorn<1->mlflow-skinny==3.2.0->mlflow) (0.16.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.2.0->mlflow) (5.0.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.2.0->mlflow) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.2.0->mlflow) (4.9)\nRequirement already satisfied: anyio<5,>=3.6.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.2.0->mlflow) (4.10.0)\nRequirement already satisfied: sniffio>=1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-89eafeaa-68a1-4d22-977d-95fb7f7e8eb7/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.2.0->mlflow) (1.3.1)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.2.0->mlflow) (0.4.8)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install mlflow\n",
    "%pip install -qU databricks-langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d274b9de-57f2-44d9-8477-03d3b3b36b32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4b7fefc-e498-40ca-9504-b27b55ab9d7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Please enter the research topic:  future of AI healthcare"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "--- \n",
       "*Running Research Agent...*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "I'd be happy to research the future of AI in healthcare for you. To provide the most relevant and comprehensive report, could you please clarify a few details:\n",
       "\n",
       "**Scope & Focus:**\n",
       "- Are you interested in specific areas of AI healthcare (e.g., diagnostics, drug discovery, personalized medicine, robotic surgery, telemedicine)?\n",
       "- Do you want to focus on particular timeframes (e.g., next 5 years, next decade, long-term projections)?\n",
       "\n",
       "**Geographic Focus:**\n",
       "- Should this cover global trends or focus on specific regions/countries?\n",
       "\n",
       "**Perspective:**\n",
       "- Are you looking at this from a particular angle (e.g., business opportunities, clinical applications, regulatory challenges, patient outcomes)?\n",
       "\n",
       "**Report Format:**\n",
       "- What level of detail would you prefer (executive summary, comprehensive analysis, technical deep-dive)?\n",
       "- Are there specific sections you'd like included (market projections, key players, challenges, opportunities)?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\n",
       "Your response:  1. drug discovery 2. global trends 3. clinical applications 4. technical deep-dive, challenges"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "--- \n",
       "*Running Research Agent...*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Workspace/Users/jason.yip@tredence.com/odr/open_deep_research/src/open_deep_research/deep_researcher.py:298: RuntimeWarning: coroutine 'Pregel.ainvoke' was never awaited\n  HumanMessage(content=tool_call[\"args\"][\"research_topic\"])\nRuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "# Research Complete"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "# The Future of AI in Drug Discovery: A Comprehensive Technical Analysis\n",
       "\n",
       "## Current State and Emerging AI Technologies in Drug Discovery\n",
       "\n",
       "Artificial intelligence has fundamentally transformed the pharmaceutical industry's approach to drug discovery, introducing unprecedented capabilities across the entire drug development pipeline. The current landscape showcases sophisticated AI applications that are revolutionizing traditional methodologies and accelerating the path from laboratory to clinic.\n",
       "\n",
       "### Target Identification and Validation\n",
       "\n",
       "Modern AI systems leverage advanced machine learning algorithms to identify novel therapeutic targets with remarkable precision. Deep learning models analyze vast genomic datasets, protein structures, and disease pathways to predict previously unknown drug targets. Graph neural networks have emerged as particularly powerful tools for understanding complex biological networks and protein-protein interactions. These systems can process multi-omics data, including genomics, proteomics, and metabolomics, to identify targets that traditional methods might overlook.\n",
       "\n",
       "Natural language processing (NLP) technologies are simultaneously mining decades of scientific literature to extract hidden relationships between genes, proteins, and diseases. These AI systems can identify potential targets by analyzing patterns across millions of research papers, patents, and clinical reports, effectively serving as intelligent research assistants that never tire of reading scientific literature.\n",
       "\n",
       "### Lead Compound Discovery and Optimization\n",
       "\n",
       "Generative AI models have revolutionized the process of molecular design and lead optimization. Variational autoencoders (VAEs), generative adversarial networks (GANs), and transformer-based models can now generate novel molecular structures with desired properties. These systems learn from vast chemical databases to understand the relationship between molecular structure and biological activity, enabling the design of compounds with optimized pharmacokinetic and pharmacodynamic properties.\n",
       "\n",
       "Reinforcement learning algorithms are being employed to navigate the vast chemical space more efficiently than traditional high-throughput screening methods. These systems can explore millions of potential compounds virtually, identifying promising candidates for synthesis and testing. Advanced molecular dynamics simulations powered by AI can predict drug-target interactions with increasing accuracy, reducing the need for extensive laboratory testing in early stages.\n",
       "\n",
       "### Clinical Trial Design and Patient Stratification\n",
       "\n",
       "AI technologies are transforming clinical trial design through sophisticated patient stratification algorithms and predictive modeling. Machine learning models analyze electronic health records, genetic profiles, and biomarker data to identify optimal patient populations for specific trials. These systems can predict patient responses to treatments, enabling more precise inclusion and exclusion criteria that improve trial success rates.\n",
       "\n",
       "Digital twin technologies are emerging as powerful tools for simulating clinical trials before they begin. These AI-powered models can predict trial outcomes, optimize dosing regimens, and identify potential safety concerns before human testing commences. Natural language processing systems are also streamlining the regulatory submission process by automatically generating and reviewing clinical trial documentation.\n",
       "\n",
       "### Regulatory Approval Pathways\n",
       "\n",
       "AI is increasingly being integrated into regulatory processes, with agencies worldwide developing frameworks for evaluating AI-driven drug discovery. Machine learning models are being used to predict regulatory approval likelihood based on preclinical and clinical data patterns. These systems analyze historical approval data to identify factors that contribute to successful regulatory submissions.\n",
       "\n",
       "Automated pharmacovigilance systems powered by AI are enhancing post-market surveillance capabilities. These systems can detect adverse events and safety signals from diverse data sources, including social media, electronic health records, and spontaneous reporting systems, providing real-time safety monitoring capabilities that surpass traditional methods.\n",
       "\n",
       "## Global Trends and Regional Developments\n",
       "\n",
       "The adoption of AI in drug discovery varies significantly across global markets, reflecting differences in regulatory environments, investment patterns, and technological infrastructure. Understanding these regional variations is crucial for comprehending the future trajectory of AI-driven pharmaceutical innovation.\n",
       "\n",
       "### North American Market Leadership\n",
       "\n",
       "North America, particularly the United States, continues to lead in AI drug discovery innovation, driven by substantial venture capital investment and a supportive regulatory environment. The FDA has established clear pathways for AI-driven drug development, including guidance documents for machine learning-based medical devices and drug development tools. Major pharmaceutical companies in the region have formed extensive partnerships with AI startups, creating a robust ecosystem for innovation.\n",
       "\n",
       "The National Institutes of Health (NIH) has launched several initiatives supporting AI in drug discovery, including the Accelerating Medicines Partnership (AMP) program, which leverages AI to identify new therapeutic targets for complex diseases. Academic institutions across the United States are establishing dedicated AI drug discovery centers, creating a pipeline of trained researchers and novel technologies.\n",
       "\n",
       "### European Integration and Collaboration\n",
       "\n",
       "Europe has adopted a more collaborative approach to AI drug discovery, with the European Medicines Agency (EMA) developing harmonized guidelines for AI applications across member states. The European Union's Horizon Europe program has allocated significant funding for AI-driven pharmaceutical research, emphasizing cross-border collaboration and data sharing initiatives.\n",
       "\n",
       "The European approach emphasizes ethical AI development and data privacy, with GDPR"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "[\"tr-16c3f82eda6cb415e6d41ce60007b51d\", \"tr-bf5335fb365cacc322de80f5531f42ed\"]",
      "text/plain": [
       "[Trace(trace_id=tr-16c3f82eda6cb415e6d41ce60007b51d), Trace(trace_id=tr-bf5335fb365cacc322de80f5531f42ed)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import asyncio\n",
    "from uuid import uuid4\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "# Before importing the project files, make sure the src directory is in the Python path.\n",
    "# This is usually handled by installing the package in editable mode (`uv pip install -e .`)\n",
    "# as recommended in the README.\n",
    "from open_deep_research.deep_researcher import deep_researcher\n",
    "from open_deep_research.state import AgentState\n",
    "\n",
    "# For rich output in notebooks that can render HTML/Markdown\n",
    "try:\n",
    "    from IPython.display import display, Markdown\n",
    "    IS_NOTEBOOK = True\n",
    "except ImportError:\n",
    "    IS_NOTEBOOK = False\n",
    "\n",
    "\n",
    "async def main():\n",
    "    \"\"\"\n",
    "    An example of how to run the Open Deep Research agent interactively,\n",
    "    handling the clarification step. This is useful for environments like\n",
    "    Databricks notebooks or local terminals.\n",
    "    \"\"\"\n",
    "    # 1. Set up your environment\n",
    "    # Make sure you have OPENAI_API_KEY, TAVILY_API_KEY, etc., set in your environment.\n",
    "    # You can copy .env.example to .env and fill in your keys.\n",
    "\n",
    "    # 2. Define the initial input for the research agent\n",
    "    research_topic = input(\"Please enter the research topic: \")\n",
    "    messages = [HumanMessage(content=research_topic)]\n",
    "\n",
    "    # 3. Configure the agent\n",
    "    # A unique thread_id is important for keeping conversations separate.\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": str(uuid4()),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 4. Start the interactive loop\n",
    "    while True:\n",
    "        if IS_NOTEBOOK:\n",
    "            display(Markdown(\"--- \\n*Running Research Agent...*\\n\"))\n",
    "        else:\n",
    "            print(\"\\n--- Running Research Agent ---\\n\")\n",
    "\n",
    "        # The agent is a LangGraph object, which you can invoke.\n",
    "        # We pass the current message history to the agent.\n",
    "        final_state: AgentState = await deep_researcher.ainvoke(\n",
    "            {\"messages\": messages}, config\n",
    "        )\n",
    "\n",
    "        # The state contains the full message history. We'll update our local\n",
    "        # list with the messages from the agent's run.\n",
    "        messages = final_state[\"messages\"]\n",
    "\n",
    "        # 5. Check for a final report\n",
    "        final_report = final_state.get(\"final_report\")\n",
    "        if final_report:\n",
    "            if IS_NOTEBOOK:\n",
    "                display(Markdown(\"# Research Complete\"))\n",
    "                display(Markdown(final_report))\n",
    "            else:\n",
    "                print(\"\\n--- Research Complete ---\\n\")\n",
    "                print(final_report)\n",
    "            break\n",
    "\n",
    "        # 6. If no report, the agent has likely asked a clarifying question.\n",
    "        last_message = messages[-1]\n",
    "        if isinstance(last_message, AIMessage):\n",
    "            if IS_NOTEBOOK:\n",
    "                display(Markdown(last_message.content))\n",
    "            else:\n",
    "                print(f\"\\nAI: {last_message.content}\")\n",
    "\n",
    "            # Prompt the user for their response to the AI's question\n",
    "            # In a notebook, input() renders as a textbox.\n",
    "            user_response = input(\"\\nYour response: \")\n",
    "            messages.append(HumanMessage(content=user_response))\n",
    "\n",
    "# In Databricks notebooks, use 'await main()' instead of 'asyncio.run(main())'\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1b2c3d4-e5f6-7890-1234-567890abcdef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": "Test Multi-MCP"
    }
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from uuid import uuid4\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "from open_deep_research.deep_researcher import deep_researcher\n",
    "from open_deep_research.state import AgentState\n",
    "from open_deep_research.utils import get_all_tools\n",
    "from open_deep_research.configuration import MCPConfig, MCPServerConfig\n",
    "\n",
    "try:\n",
    "    from IPython.display import display, Markdown\n",
    "    IS_NOTEBOOK = True\n",
    "except ImportError:\n",
    "    IS_NOTEBOOK = False\n",
    "\n",
    "\n",
    "async def test_multi_mcp():\n",
    "    \"\"\"\n",
    "    An example of how to run the Open Deep Research agent with multiple MCP servers.\n",
    "    \"\"\"\n",
    "    # 1. Define the MCP server configurations\n",
    "    mcp_servers = [\n",
    "        MCPServerConfig(\n",
    "            url=\"https://adb-8333330282859393.13.azuredatabricks.net/api/2.0/mcp/genie/01f08636c357189e81d584d6bbfef815\",\n",
    "            auth_required=True,\n",
    "        ),\n",
    "        MCPServerConfig(\n",
    "            url=\"https://this-is-a-dummy-url.com/api/2.0/mcp/genie/dummy-mcp-server\",\n",
    "            auth_required=False,\n",
    "        ),\n",
    "        MCPServerConfig(\n",
    "            url=\"https://another-dummy-url.com/api/2.0/mcp/genie/another-dummy-mcp-server\",\n",
    "            auth_required=True,\n",
    "            token=\"directly-provided-token\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # 2. Define the initial input for the research agent\n",
    "    research_topic = \"test\"\n",
    "    messages = [HumanMessage(content=research_topic)]\n",
    "\n",
    "    # 3. Configure the agent\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": str(uuid4()),\n",
    "            \"mcp_config\": MCPConfig(\n",
    "                servers=mcp_servers,\n",
    "                tools=[\"all\"],\n",
    "            )\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 4. Get all available tools\n",
    "    all_tools = await get_all_tools(config)\n",
    "    \n",
    "    # 5. Print the names of all the tools\n",
    "    if IS_NOTEBOOK:\n",
    "        display(Markdown(\"## Available Tools:\"))\n",
    "        for tool in all_tools:\n",
    "            tool_name = tool.name if hasattr(tool, \"name\") else tool.get(\"name\", \"web_search\")\n",
    "            display(Markdown(f\"- {tool_name}\"))\n",
    "    else:\n",
    "        print(\"Available Tools:\")\n",
    "        for tool in all_tools:\n",
    "            tool_name = tool.name if hasattr(tool, \"name\") else tool.get(\"name\", \"web_search\")\n",
    "            print(f\"- {tool_name}\")\n",
    "\n",
    "await test_multi_mcp()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "LangGraph DeepReearch",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}